{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "Read:\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()\n",
    "os.getenv(\"MY_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic sequence of steps for function calling is as follows:\n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](first.png \"function_calling\")\n",
    "\n",
    "![Alt text](second.png \"function_calling\")\n",
    "\n",
    "https://www.linkedin.com/pulse/azure-openai-function-calling-tarun-sharma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "https://github.com/openai/openai-python/tree/main/src/openai/types/chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Welcome\":\"You can check weather of lahore & islamabad\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get(\"http://weather-forecast:8001\") # use hostname/container name to access\n",
    "print(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<PreparedRequest [GET]>\n"
     ]
    }
   ],
   "source": [
    "print(data.status_code)\n",
    "print(data.request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_Xbn7OcI7GTIxpbA6C1ZzEkrq', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_pvmgXmPI4PgpuIdlQJ6XJXYO', function=Function(arguments='{\"location\": \"Murree\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_G3EpL0YUUd48NU1rA3spNs00', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* First Reponse Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_Xbn7OcI7GTIxpbA6C1ZzEkrq', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_pvmgXmPI4PgpuIdlQJ6XJXYO', function=Function(arguments='{\"location\": \"Murree\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_G3EpL0YUUd48NU1rA3spNs00', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* Second Request Messages: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'what the weather in lahore, muree and islamabad?'},\n",
       " ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Xbn7OcI7GTIxpbA6C1ZzEkrq', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_pvmgXmPI4PgpuIdlQJ6XJXYO', function=Function(arguments='{\"location\": \"Murree\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_G3EpL0YUUd48NU1rA3spNs00', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]),\n",
       " {'tool_call_id': 'call_Xbn7OcI7GTIxpbA6C1ZzEkrq',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Lahore\\\\\", \\\\\"temperature\\\\\": \\\\\"72\\\\\", \\\\\"unit\\\\\": \\\\\"fahrenheit\\\\\"}\"'},\n",
       " {'tool_call_id': 'call_pvmgXmPI4PgpuIdlQJ6XJXYO',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Murree\\\\\", \\\\\"temperature\\\\\": \\\\\"10\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'},\n",
       " {'tool_call_id': 'call_G3EpL0YUUd48NU1rA3spNs00',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Islamabad\\\\\", \\\\\"temperature\\\\\": \\\\\"22\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "* Second Response:  {'id': 'chatcmpl-A7i618nJaeIlixRRcGhoMfBPz0oTe', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, the weather in Lahore is 72°F, in Murree it is 10°C, and in Islamabad it is 22°C.', refusal=None, role='assistant', function_call=None, tool_calls=None))], 'created': 1726401165, 'model': 'gpt-3.5-turbo-1106', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_54b3a4486f', 'usage': CompletionUsage(completion_tokens=29, prompt_tokens=177, total_tokens=206, completion_tokens_details={'reasoning_tokens': 0})}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Currently, the weather in Lahore is 72°F, in Murree it is 10°C, and in Islamabad it is 22°C.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion, ChatCompletionMessage\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "client: OpenAI = OpenAI()\n",
    "\n",
    "def call_fastapi_get_current_weather(location:str, unit: str= \"fahrenheit\")->str:\n",
    "    url = \"http://weather-forecast:8001/get_current_weather\"\n",
    "    payloads = {\"location\": location, \"unit\":unit}\n",
    "    response =requests.post(url,json=payloads)\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def run_conversation(main_request: str)->str:\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": main_request}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\", \"unit\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_book_flight\",\n",
    "                \"description\": \"Book a flight for a specific destination and date.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The destination city, e.g. Paris, Tokyo\",\n",
    "                        },\n",
    "                        # \"date\": {\n",
    "                        #     \"type\": \"string\",\n",
    "                        #     \"format\": \"date\",\n",
    "                        #     \"description\": \"The date of the flight, e.g. 2024-09-30\",\n",
    "                        # },\n",
    "                        \"passenger_count\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The number of passengers for the flight\",\n",
    "                            \"default\": 1,\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"destination\", \"passenger_count\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # First Request\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message: ChatCompletionMessage = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "    print(\"---------------\")\n",
    "\n",
    "    tool_calls = response_message.tool_calls\n",
    "    display(\"* First Reponse Tool Calls: \", list(tool_calls))\n",
    "    print(\"---------------\")\n",
    "    \n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        # available_functions = {\n",
    "        #     \"get_current_weather\": get_current_weather,\n",
    "        #     \"get_book_flight\": get_book_flight\n",
    "        # }  # only one function in this example, but you can have multiple\n",
    "        # available_functions[\"get_current_weather\"]()\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        \n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            function_response = call_fastapi_get_current_weather(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\")    \n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "            # elif function_name == \"get_current_weather\":\n",
    "            #     function_response = function_to_call(\n",
    "            #     location=function_args.get(\"location\"),\n",
    "            #     unit=function_args.get(\"unit\"),\n",
    "            #     )\n",
    "            #     messages.append(\n",
    "            #     {\n",
    "            #         \"tool_call_id\": tool_call.id,\n",
    "            #         \"role\": \"tool\",\n",
    "            #         \"name\": function_name,\n",
    "            #         \"content\": function_response,\n",
    "            #     }\n",
    "            # )  # extend conversation with function response\n",
    "        display(\"* Second Request Messages: \", list(messages))\n",
    "        print(\"---------------\")\n",
    "        second_response: ChatCompletion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        return second_response.choices[0].message.content\n",
    "run_conversation(\"what the weather in lahore, muree and islamabad?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
